{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sujet\n",
    "Vous obtiendrez un ensemble de données, qui montre les notes de films par les utilisateurs.  Téléchargez le jeu de données .  \n",
    "L'ensemble de données fait partie de l'ensemble de données gratuit Movielens 100-k.  \n",
    "Dans le fichier Lisez-moi, vous trouverez des informations sur la structure de cet ensemble de données spécifique :\n",
    "\n",
    "u.data :\n",
    "- L'ensemble complet de données u, 100 000 évaluations par 943 utilisateurs sur 1 682 éléments.\n",
    "- Chaque utilisateur a évalué au moins 20 films.\n",
    "- Les utilisateurs et les éléments sont numérotées consécutivement à partir de 1.\n",
    "- Les données sont aléatoirement commandé.\n",
    "- Il s'agit d'une liste séparée par des tabulations\n",
    "- L'identifiant utilisateur | identifiant de l'article | note | horodatage.\n",
    "- Les horodatages sont en secondes unix depuis le 01/01/1970 UTC  \n",
    "\n",
    "### Votre tâche :\n",
    "- utilisez PySpark pour charger les données et compter la fréquence d'apparition de chaque valeur.  \n",
    "- Bonuspoints, si vous donnez même le pourcentage d'apparition de chaque valeur.\n",
    "- Postez une capture d'écran de votre code et de vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "#2- Import StructField, StructType, StringType, IntegerType, FloatType\n",
    "from pyspark.sql.types import (StructField, IntegerType, StructType)\n",
    "\n",
    "#8 controle s'il reste des valeurs nulles\n",
    "from pyspark.sql.functions import desc\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a spark session and declare it in spark variable\n",
    "\n",
    "spark = SparkSession.builder.appName('exercice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+---------+\n",
      "|user_id|item_id|rating|timestamp|\n",
      "+-------+-------+------+---------+\n",
      "|    196|    242|     3|881250949|\n",
      "|    186|    302|     3|891717742|\n",
      "|     22|    377|     1|878887116|\n",
      "|    244|     51|     2|880606923|\n",
      "|    166|    346|     1|886397596|\n",
      "|    298|    474|     4|884182806|\n",
      "|    115|    265|     2|881171488|\n",
      "|    253|    465|     5|891628467|\n",
      "|    305|    451|     3|886324817|\n",
      "|      6|     86|     3|883603013|\n",
      "|     62|    257|     2|879372434|\n",
      "|    286|   1014|     5|879781125|\n",
      "|    200|    222|     5|876042340|\n",
      "|    210|     40|     3|891035994|\n",
      "|    224|     29|     3|888104457|\n",
      "|    303|    785|     3|879485318|\n",
      "|    122|    387|     5|879270459|\n",
      "|    194|    274|     2|879539794|\n",
      "|    291|   1042|     4|874834944|\n",
      "|    234|   1184|     2|892079237|\n",
      "+-------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "\n",
    "# user id | item id | rating | timestamp\n",
    "\n",
    "my_schema = StructType([\n",
    "    StructField('user_id', IntegerType(), False),\n",
    "    StructField('item_id', IntegerType(), False),\n",
    "    StructField('rating', IntegerType(), False),\n",
    "    StructField('timestamp', IntegerType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# cf inferSchema = True\n",
    "df = spark.read.option('delimiter', '\\\\t').csv('u-data', schema = my_schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------------------------+\n",
      "|user_id|Nombre_films_evalues|pourcentage_du_total_évalué|\n",
      "+-------+--------------------+---------------------------+\n",
      "|    405|                 737|          78.15482502651113|\n",
      "|    655|                 685|          72.64050901378579|\n",
      "|     13|                 636|          67.44432661717921|\n",
      "|    450|                 540|          57.26405090137858|\n",
      "|    276|                 518|          54.93107104984093|\n",
      "|    416|                 493|         52.279957582184515|\n",
      "|    537|                 490|          51.96182396606575|\n",
      "|    303|                 484|          51.32555673382821|\n",
      "|    234|                 480|          50.90137857900318|\n",
      "|    393|                 448|          47.50795334040297|\n",
      "|    181|                 435|         46.129374337221634|\n",
      "|    279|                 434|          46.02332979851538|\n",
      "|    429|                 414|          43.90243902439025|\n",
      "|    846|                 405|          42.94803817603393|\n",
      "|      7|                 403|          42.73594909862142|\n",
      "|     94|                 400|         42.417815482502654|\n",
      "|    682|                 399|           42.3117709437964|\n",
      "|    308|                 397|          42.09968186638388|\n",
      "|     92|                 388|         41.145281018027575|\n",
      "|    293|                 388|         41.145281018027575|\n",
      "+-------+--------------------+---------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#groupby pour obtenir le nombre de fils évalués et le pourcentage par user_id\n",
    "\n",
    "groupby_user_id = df.groupBy(\"user_id\").count()\n",
    "\n",
    "tot = groupby_user_id.count()\n",
    "\n",
    "groupby_user_id2 = df.groupBy(\"user_id\") \\\n",
    "  .count() \\\n",
    "  .withColumnRenamed('count', 'Nombre_films_evalues') \\\n",
    "  .withColumn('pourcentage_du_total_évalué', (F.col('Nombre_films_evalues') * 100) / tot ) \\\n",
    "  .sort(desc(\"pourcentage_du_total_évalué\")) \\\n",
    "  .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3755b735588d4303beb95518f2ab4e1c49ea1461d509c805a65d62cd2a8f700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
