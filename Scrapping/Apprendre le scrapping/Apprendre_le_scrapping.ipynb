{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.cours-gratuit.com/tutoriel-python/tutoriel-python-comment-scrapper-un-site-en-python'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#effectuer une requête\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "#code 200 = tout va bien !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# si c'est pas ok, on peut créer une condition\n",
    "\n",
    "if response.ok :\n",
    "    print(response)\n",
    "else :\n",
    "    print (\"il y a un problème bichette !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avoir le code html de la page\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c'est cool mais on en fait quoi ? On peut utiliser beautifulsoup par exemple\n",
    "if response.ok :\n",
    "    soup = BeautifulSoup(response.text)\n",
    "\n",
    "#concrètement il ne se passe rien, j'ai toujours mon code htlm, la différence c'est que maintenant je vais pouvoir le parser\n",
    "#parser = Analyser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Tuto Web scraping Python : Extraire les données d'un site web - Tutoriel Python</title>\n"
     ]
    }
   ],
   "source": [
    "#soup.find('') => permet de localiser un sélecteur en fonction d'un sélecteur css\n",
    "\n",
    "if response.ok :\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    title = soup.find('title') #on met juste le nom de la balise\n",
    "    print(title)\n",
    "\n",
    "#Réponse : Tuto Web scraping Python : Extraire les données d'un site web - Tutoriel Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Tuto Web scraping Python : Extraire les données d'un site web - Tutoriel Python</title>\n"
     ]
    }
   ],
   "source": [
    "# Il se peut qu'il nous demande quel parser utiliser, si on ne précise pas il en prend un par défaut (en général lxml). \n",
    "# Si on est embêté, il suffit de préciser le parser comme argument dans la fonction\n",
    "\n",
    "if response.ok :\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    title = soup.find('title') #on met juste le nom de la balise\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuto Web scraping Python : Extraire les données d'un site web - Tutoriel Python\n"
     ]
    }
   ],
   "source": [
    "# si on veut le contenu sans les balises, très simple il suffit de lui indiquer dans le print\n",
    "\n",
    "if response.ok :\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    title = soup.find('title') #on met juste le nom de la balise\n",
    "    print(title.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sélectionner des liens pour ensuite pouvoir aller sur des pages, il faut examiner les pages (clic droit => inspecter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "# pour sélectionner plusieurs éléments nous allons utiliser findAll et pour connaitre le nombre de cellule\n",
    "# td qui sont des cellules et tr qui sont des colonnes\n",
    "\n",
    "if response.ok :\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    tds = soup.findAll('td') \n",
    "    print(len(title.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avec une boucle :)\n",
    "\n",
    "if response.ok :\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    tds = soup.findAll('td') \n",
    "    [print(str(td) + '\\n\\n') for td in tds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# je change de page pour une page wikipedia\n",
    "\n",
    "url = 'http://example.python-scraping.com/'\n",
    "response2 = requests.get(url)\n",
    "response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "# je souhaite savoir combien de cellule <td> je dispose dans cette page\n",
    "\n",
    "url = 'http://example.python-scraping.com/'\n",
    "response2 = requests.get(url)\n",
    "\n",
    "if response2.ok :\n",
    "    soup = BeautifulSoup(response2.text, 'lxml')\n",
    "    tds = soup.findAll('td') \n",
    "    print(len(title.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ainsi je vais obtenir la liste de tous les <td>\n",
    "\n",
    "url = 'http://example.python-scraping.com/'\n",
    "response2 = requests.get(url)\n",
    "\n",
    "if response2.ok :\n",
    "    soup = BeautifulSoup(response2.text, 'lxml')\n",
    "    tds = soup.findAll('td') \n",
    "    [print(str(td) + '\\n\\n') for td in tds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<td>\\n    <span class=\"datasortkey\" data-sort-value=\"Japon\"><span class=\"flagicon\">\\n        <a class=\"image\" href=\"/wiki/Fichier:Flag_of_Japan.svg\" title=\"Drapeau du Japon\"><img alt=\"Drapeau du Japon\" class=\"noviewer thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"13\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Flag_of_Japan.svg/20px-Flag_of_Japan.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Flag_of_Japan.svg/30px-Flag_of_Japan.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Flag_of_Japan.svg/40px-Flag_of_Japan.svg.png 2x\" width=\"20\"/></a> \\n    </span>\\n        <a href=\"/wiki/Japon\" title=\"Japon\">Japon</a>\\n    </span>\\n</td>\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a ce stade j'ai extrait ma liste de td\n",
    "#nous allons en décomposer un pour analyser\n",
    "\n",
    "'''\n",
    "<td>\n",
    "    <span class=\"datasortkey\" data-sort-value=\"Japon\"><span class=\"flagicon\">\n",
    "        <a class=\"image\" href=\"/wiki/Fichier:Flag_of_Japan.svg\" title=\"Drapeau du Japon\"><img alt=\"Drapeau du Japon\" class=\"noviewer thumbborder\" data-file-height=\"600\" data-file-width=\"900\" decoding=\"async\" height=\"13\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Flag_of_Japan.svg/20px-Flag_of_Japan.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Flag_of_Japan.svg/30px-Flag_of_Japan.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Flag_of_Japan.svg/40px-Flag_of_Japan.svg.png 2x\" width=\"20\"/></a> \n",
    "    </span>\n",
    "        <a href=\"/wiki/Japon\" title=\"Japon\">Japon</a>\n",
    "    </span>\n",
    "</td>\n",
    "'''\n",
    "\n",
    "#nous allons pouvoir créer une liste pour récupérer les éléments\n",
    "#info : quand on veut récupérer un élément à l'intérieur d'une balise on utilise des crochets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.python-scraping.com/places/default/view/Afghanistan-1\n",
      "http://example.python-scraping.com/places/default/view/Aland-Islands-2\n",
      "http://example.python-scraping.com/places/default/view/Albania-3\n",
      "http://example.python-scraping.com/places/default/view/Algeria-4\n",
      "http://example.python-scraping.com/places/default/view/American-Samoa-5\n",
      "http://example.python-scraping.com/places/default/view/Andorra-6\n",
      "http://example.python-scraping.com/places/default/view/Angola-7\n",
      "http://example.python-scraping.com/places/default/view/Anguilla-8\n",
      "http://example.python-scraping.com/places/default/view/Antarctica-9\n",
      "http://example.python-scraping.com/places/default/view/Antigua-and-Barbuda-10\n"
     ]
    }
   ],
   "source": [
    "# on va mettre dans une liste toutes nos URL\n",
    "\n",
    "url = 'http://example.python-scraping.com/'\n",
    "response2 = requests.get(url)\n",
    "\n",
    "if response2.ok :\n",
    "\n",
    "    links = []\n",
    "\n",
    "    soup = BeautifulSoup(response2.text, 'lxml')\n",
    "    tds = soup.findAll('td') \n",
    "\n",
    "    #print(tds)\n",
    "\n",
    "    for td in tds :\n",
    "        a = td.find('a') ## on cherche la balise a\n",
    "        link = a['href'] #lorsque l'on veut récupérer un attribut dans une balise, on utilise les [], donc dans a on veut l'attribut <href>\n",
    "        links.append(link)\n",
    "        \n",
    "        print('http://example.python-scraping.com' + link) #concat avec le début de l'url de base et l'url trouvé => bien testé pour vérifeir que c'est ok\n",
    "\n",
    "#A ce stade nous avons toutes les url de la page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maintenant nous allons itérer pour pouvoir répéter ce code, à chaque passage on va incrémenter qqch pour pouvoir accéder à la page suivante\n",
    "#avant ça il faut recherche le nombre de page du site que l'on a ou que l'on a besoin de scrapper\n",
    "#sur ce site il y a 25 pages\n",
    "#je remet l'entièreté du code pour qu'à chaque fois nous puissions le relire et le comprendre dans son intégralité\n",
    "\n",
    "\n",
    "links = [] #je sors ma liste de ma boucle\n",
    "\n",
    "for i in range(26) : #de 0 à 25 pages\n",
    "    url = 'http://example.python-scraping.com/places/default/index/' + str(i) #ici il faut noter l'url complète qui ne change jamais entre les pages + le num de la page en str\n",
    "    response2 = requests.get(url)\n",
    "\n",
    "    if response2.ok :      \n",
    "        soup = BeautifulSoup(response2.text, 'lxml')\n",
    "        tds = soup.findAll('td') \n",
    "\n",
    "        for td in tds :\n",
    "            a = td.find('a') \n",
    "            link = a['href'] \n",
    "            links.append('http://example.python-scraping.com' + link)\n",
    "            \n",
    "print(links) \n",
    "\n",
    "#grâce à la première url je vais crapper chaque page\n",
    "#la dernière url va me permettre de récupérer toutes les url de chaque page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test de notre précédente formule de code\n",
    "#pour savoir combien de lien je récupère sur chaque page je print le numéro de la page et le len de la liste links\n",
    "\n",
    "links = [] \n",
    "\n",
    "for i in range(26) : #de 0 à 25 pages\n",
    "    url = 'http://example.python-scraping.com/places/default/index/' + str(i) #ici il faut noter l'url complète qui ne change jamais entre les pages + le num de la page en str\n",
    "    response2 = requests.get(url)\n",
    "\n",
    "    if response2.ok :    \n",
    "        print(\"page:\" + str(i))   #pour savoir combien de lien je récupère sur chaque page je print le numéro de la page et le len de la liste links\n",
    "\n",
    "        soup = BeautifulSoup(response2.text, 'lxml')\n",
    "        tds = soup.findAll('td') \n",
    "\n",
    "        for td in tds :\n",
    "            a = td.find('a') \n",
    "            link = a['href'] \n",
    "            links.append('http://example.python-scraping.com' + link)\n",
    "            \n",
    "    print(len(links) ) #pour savoir combien de lien je récupère sur chaque page je print le numéro de la page et le len de la liste links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si jamais on se fait bloquer car on requête trop on peut importer la bibliothèque time et mettre une seconde de pause entre nos requêtes, ainsi on évite de se faire bloquer\n",
    "import time\n",
    "\n",
    "links = [] \n",
    "\n",
    "for i in range(26) : #de 0 à 25 pages\n",
    "    url = 'http://example.python-scraping.com/places/default/index/' + str(i) #ici il faut noter l'url complète qui ne change jamais entre les pages + le num de la page en str\n",
    "    response2 = requests.get(url)\n",
    "\n",
    "    if response2.ok :    \n",
    "        print(\"page:\" + str(i))   #pour savoir combien de lien je récupère sur chaque page je print le numéro de la page et le len de la liste links\n",
    "\n",
    "        soup = BeautifulSoup(response2.text, 'lxml')\n",
    "        tds = soup.findAll('td') \n",
    "\n",
    "        for td in tds :\n",
    "            a = td.find('a') \n",
    "            link = a['href'] \n",
    "            links.append('http://example.python-scraping.com' + link)\n",
    "\n",
    "        time.sleep(1)  #je met une seconde de pause entre mes requpetes afin de ne pas me faire bloquer, si ce n'est pas suffisant, augmenter le temps !\n",
    "\n",
    "    print(len(links) ) #pour savoir combien de lien je récupère sur chaque page je print le numéro de la page et le len de la liste links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links = [] \n",
    "\n",
    "for i in range(26) : \n",
    "    url = 'http://example.python-scraping.com/places/default/index/' + str(i) \n",
    "    response2 = requests.get(url)\n",
    "\n",
    "    if response2.ok :    \n",
    "        \n",
    "        soup = BeautifulSoup(response2.text, 'lxml')\n",
    "        tds = soup.findAll('td') \n",
    "\n",
    "        for td in tds :\n",
    "            a = td.find('a') \n",
    "            link = a['href'] \n",
    "            links.append('http://example.python-scraping.com' + link)\n",
    "\n",
    "        time.sleep(1)  \n",
    "\n",
    "    print(links) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color: #669900\"> Maintenant il va falloir que je stocke mes données, et pour ça il y a plein de façons :json, csv...</span>\n",
    "#### On va utiliser la fonction <span style=\"color: #FF5733 \">***open***</span> qui va nous permettre d'ouvrir un fichier en le créant avec le mode <span style=\"color: #FF5733 \">***w***</span> (cf  ci-dessous)\n",
    "_Plus d'infos ici : https://www.geeksforgeeks.org/python-open-function/#:~:text=The%20python%20open()%20function,that%20we%20want%20to%20open._\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color: #99CCFF\"> __Syntaxe__</span> : open(file_name, mode) \n",
    "\n",
    "<span style=\"color: #99CCFF\">__Paramètres__</span>:\n",
    "\n",
    "1- <span style=\"color: ##339900 \">***file_name***</span> : Ce paramètre comme son nom l'indique, est le nom du fichier que l'on souhaite ouvrir.\n",
    "\n",
    "2- <span style=\"color: ##339900 \">***mode***</span> : ce paramètre est une chaîne utilisée pour spécifier le mode dans lequel le fichier doit être ouvert.\n",
    "    \n",
    "<span style=\"color: #99CCFF\">_Les chaînes suivantes peuvent être utilisées pour activer un mode spécifique_ : </span>\n",
    "  \n",
    "<span style=\"color: #FF5733 \">***r***</span> : Cette chaîne est utilisée pour lire (uniquement) le fichier. Il est passé par défaut si aucun paramètre n'est fourni et renvoie une erreur si un tel fichier n'existe pas.  \n",
    "<span style=\"color: #FF5733 \">***w***</span> : cette chaîne est utilisée pour écrire sur/au-dessus du fichier. Si le fichier avec le nom fourni n'existe pas, il en crée un pour vous.  \n",
    "<span style=\"color: #FF5733 \">***a***</span>: Cette chaîne est utilisée pour ajouter (ajouter) du contenu à un fichier existant. Si aucun fichier de ce type n'existe, il en crée un pour vous.  \n",
    "<span style=\"color: #FF5733 \">***x***</span>: cette chaîne est utilisée pour créer un fichier spécifique.  \n",
    "<span style=\"color: #FF5733 \">***b***</span> : Cette chaîne est utilisée lorsque l'utilisateur souhaite manipuler le fichier en mode binaire. Ceci est généralement utilisé pour gérer les fichiers image.  \n",
    "<span style=\"color: #FF5733 \">***t***</span> : Cette chaîne est utilisée pour manipuler les fichiers en mode texte. Par défaut, la fonction open() utilise le mode texte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfile = open('urls.txt', 'w')\\nfile.write(link +'\\n')\\nfile.close(link +'\\n')\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#création du fichier qui va contenir nos urls, que nous appelons urls.\n",
    "\n",
    "with open('urls.txt', 'w') as file :        \n",
    "    for link in links:                      # Pour chaque lien dans la liste links  \n",
    "        file.write(link +'\\n')              # nous allons écrire dans notre fichier, le lien + un retour à la ligne\n",
    "\n",
    "\n",
    "\n",
    "#with nous permet d'avoir la fermeture du fichier en dynamique donc pas besoin d'utiliser file.close()\n",
    "# cette fonction est la même que celle ci :\n",
    "'''\n",
    "file = open('urls.txt', 'w')\n",
    "file.write(link +'\\n')\n",
    "file.close(link +'\\n')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #FF5733 \">***ATTENTION***</span> : Si vous ouvrez un fichier en écriture (<span style=\"color: #FF5733 \">***w***</span>) et qu'il existe déjà, vous perdrez toutes vos données et cela vous ouvrira une page blanche.  \n",
    "Il faut donc bien penser à ouvrir ses fichiers en <span style=\"color: #FF5733 \">***r***</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.python-scraping.com/places/default/view/Afghanistan-1\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Aland-Islands-2\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Albania-3\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Algeria-4\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/American-Samoa-5\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Andorra-6\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Angola-7\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Anguilla-8\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Antarctica-9\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Antigua-and-Barbuda-10\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Argentina-11\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Armenia-12\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Aruba-13\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Australia-14\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Austria-15\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Azerbaijan-16\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bahamas-17\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bahrain-18\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bangladesh-19\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Barbados-20\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Belarus-21\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Belgium-22\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Belize-23\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Benin-24\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bermuda-25\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bhutan-26\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bolivia-27\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bonaire-Saint-Eustatius-and-Saba-28\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bosnia-and-Herzegovina-29\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Botswana-30\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bouvet-Island-31\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Brazil-32\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/British-Indian-Ocean-Territory-33\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/British-Virgin-Islands-34\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Brunei-35\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Bulgaria-36\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Burkina-Faso-37\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Burundi-38\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cambodia-39\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cameroon-40\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Canada-41\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cape-Verde-42\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cayman-Islands-43\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Central-African-Republic-44\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Chad-45\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Chile-46\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Christmas-Island-47\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cocos-Islands-48\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Colombia-49\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Comoros-50\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cook-Islands-51\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Costa-Rica-52\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Croatia-53\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cuba-54\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Curacao-55\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Cyprus-56\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Czech-Republic-57\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Democratic-Republic-of-the-Congo-58\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Denmark-59\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Djibouti-60\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Dominica-61\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Dominican-Republic-62\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/East-Timor-63\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Ecuador-64\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Egypt-65\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/El-Salvador-66\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Equatorial-Guinea-67\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Eritrea-68\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Estonia-69\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Ethiopia-70\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Faroe-Islands-71\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Fiji-72\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Finland-73\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/France-74\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/French-Guiana-75\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/French-Polynesia-76\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/French-Southern-Territories-77\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Gabon-78\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Gambia-79\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Georgia-80\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Germany-81\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Ghana-82\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Gibraltar-83\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Greece-84\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Greenland-85\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Grenada-86\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Guadeloupe-87\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Guam-88\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Guatemala-89\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Guernsey-90\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Guinea-91\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Guinea-Bissau-92\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Guyana-93\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Haiti-94\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Heard-Island-and-McDonald-Islands-95\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Honduras-96\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Hungary-97\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Iceland-98\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Indonesia-99\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Iran-100\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Iraq-101\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Ireland-102\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Isle-of-Man-103\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Israel-104\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Italy-105\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Ivory-Coast-106\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Jamaica-107\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Japan-108\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Jersey-109\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Jordan-110\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Kazakhstan-111\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Kenya-112\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Kiribati-113\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Kosovo-114\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Kuwait-115\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Kyrgyzstan-116\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Laos-117\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Latvia-118\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Lebanon-119\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Lesotho-120\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Liberia-121\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Libya-122\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Liechtenstein-123\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Lithuania-124\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Luxembourg-125\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Macedonia-126\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Madagascar-127\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Malawi-128\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Malaysia-129\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Maldives-130\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Mali-131\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Malta-132\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Marshall-Islands-133\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Martinique-134\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Mauritania-135\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Mauritius-136\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Mayotte-137\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Mexico-138\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Micronesia-139\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Moldova-140\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Monaco-141\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Mongolia-142\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Montenegro-143\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Montserrat-144\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Morocco-145\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Mozambique-146\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Myanmar-147\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Namibia-148\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Nauru-149\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Nepal-150\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Netherlands-151\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Netherlands-Antilles-152\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/New-Caledonia-153\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/New-Zealand-154\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Nicaragua-155\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Niger-156\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Nigeria-157\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Niue-158\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Norfolk-Island-159\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/North-Korea-160\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Northern-Mariana-Islands-161\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Norway-162\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Oman-163\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Pakistan-164\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Palau-165\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Palestinian-Territory-166\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Panama-167\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Papua-New-Guinea-168\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Paraguay-169\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Peru-170\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Philippines-171\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Pitcairn-172\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Poland-173\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Portugal-174\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Puerto-Rico-175\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Qatar-176\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Republic-of-the-Congo-177\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Reunion-178\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Romania-179\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Russia-180\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Rwanda-181\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saint-Barthelemy-182\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saint-Helena-183\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saint-Kitts-and-Nevis-184\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saint-Lucia-185\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saint-Martin-186\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saint-Pierre-and-Miquelon-187\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saint-Vincent-and-the-Grenadines-188\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Samoa-189\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/San-Marino-190\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Sao-Tome-and-Principe-191\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Saudi-Arabia-192\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Senegal-193\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Serbia-194\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Serbia-and-Montenegro-195\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Seychelles-196\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Sierra-Leone-197\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Singapore-198\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Sint-Maarten-199\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Slovakia-200\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Slovenia-201\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Solomon-Islands-202\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Somalia-203\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/South-Africa-204\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/South-Georgia-and-the-South-Sandwich-Islands-205\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/South-Korea-206\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/South-Sudan-207\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Spain-208\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Sri-Lanka-209\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Sudan-210\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Suriname-211\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Svalbard-and-Jan-Mayen-212\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Swaziland-213\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Sweden-214\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Switzerland-215\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Syria-216\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Tajikistan-217\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Tanzania-218\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Thailand-219\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Togo-220\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Tokelau-221\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Tonga-222\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Trinidad-and-Tobago-223\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Tunisia-224\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Turkey-225\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Turkmenistan-226\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Turks-and-Caicos-Islands-227\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Tuvalu-228\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/US-Virgin-Islands-229\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Uganda-230\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Ukraine-231\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/United-Arab-Emirates-232\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/United-Kingdom-233\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/United-States-234\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/United-States-Minor-Outlying-Islands-235\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Uruguay-236\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Uzbekistan-237\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Vanuatu-238\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Vatican-239\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Venezuela-240\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Vietnam-241\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Wallis-and-Futuna-242\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Western-Sahara-243\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Yemen-244\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Zambia-245\n",
      "\n",
      "http://example.python-scraping.com/places/default/view/Zimbabwe-246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pour pouvoir afficher mes url, les récupérer, voici le code :\n",
    "\n",
    "with open('urls.txt', 'r') as file :        \n",
    "    for row in file:                      \n",
    "        print(row)\n",
    "\n",
    "\n",
    "# tadam ! :) :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #99CCFF\"> **Note**</span>  <span style=\"color: #6699FF \">: Maintenant que l'on a récupéré nos url, on va requêter dessus et rechercher dedans ce qu'on a envie de trouver (la population etc.)</span> \n",
    "<span style=\"color: #9966FF\"> _Pour ne pas surcharger votre temps d'éxécution, on va faire notre recherche sur une seule page et ensuite on pourra itérer de pages en pages_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"url_de_test = 'http://example.python-scraping.com/places/default/view/Angola-7'\\n\\nresponse3 = requests.get(url_de_test)\\n\\nif response3.ok :    \\n    \\n    soup = BeautifulSoup(response3.text, 'lxml')\\n    country = soup.find('tr', {'id' : 'places_country_or_district__row'}).find('td', {'class' : 'w2p_fw'})\\n    population = soup.find('tr', {'id' : 'places_population__row'}).find('td', {'class' : 'w2p_fw'})\\n    print('Pays : ' + country.text + ', population : ' +  population.text)\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création de notre formule pour une page\n",
    "\n",
    "'''url_de_test = 'http://example.python-scraping.com/places/default/view/Angola-7'\n",
    "\n",
    "response3 = requests.get(url_de_test)\n",
    "\n",
    "if response3.ok :    \n",
    "    \n",
    "    soup = BeautifulSoup(response3.text, 'lxml')\n",
    "    country = soup.find('tr', {'id' : 'places_country_or_district__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "    population = soup.find('tr', {'id' : 'places_population__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "    print('Pays : ' + country.text + ', population : ' +  population.text)'''\n",
    "\n",
    "    #print('Pays : ' + str(country) + ', population : ' +  str(population)) => on peut faire comme cela, mais nous aurons les balises en print\n",
    "\n",
    "    \n",
    "#voilà !!!! Normalement on obtient : Pays : Angola, population : 13,068,161\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #99CCFF\"> **Note**</span>  <span style=\"color: #6699FF \">: Maintenant on va pouvoir itérer au travers des pages et rechercher nos infos</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itération avec notre formule ci-dessus\n",
    "\n",
    "\n",
    "with open('urls.txt', 'r') as file :               #on reprend notre fichier file :\n",
    "\n",
    "    for row in file:                               #dans lequel on va itérer              \n",
    "        url = row.strip()                          #permet de ne pas faire de retour à la ligne dans les url (supprime les caractères en début et fin de chaîne)\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.ok :    \n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "            country = soup.find('tr', {'id' : 'places_country_or_district__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "            population = soup.find('tr', {'id' : 'places_population__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "            print('Pays : ' + country.text + ', population : ' +  population.text)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "# a ce stade on obtient la liste de tous les pays et les populations\n",
    "# il y en a env 250 alors vous pouvez arrêter l'éxecution une fois que vous avez vu votre résultat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #99CCFF\"> **Création d'un fichier csv**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pays,population\n",
      "\n",
      "Afghanistan,29 121 286\n",
      "\n",
      "Aland Islands,26 711\n",
      "\n",
      "Albania,2 986 952\n",
      "\n",
      "Algeria,34 586 184\n",
      "\n",
      "American Samoa,57 881\n",
      "\n",
      "Andorra,84 000\n",
      "\n",
      "Angola,13 068 161\n",
      "\n",
      "Anguilla,13 254\n",
      "\n",
      "Antarctica,0\n",
      "\n",
      "Antigua and Barbuda,86 754\n",
      "\n",
      "Argentina,41 343 201\n",
      "\n",
      "Armenia,2 968 000\n",
      "\n",
      "Aruba,71 566\n",
      "\n",
      "Australia,21 515 754\n",
      "\n",
      "Austria,8 205 000\n",
      "\n",
      "Azerbaijan,8 303 512\n",
      "\n",
      "Bahamas,301 790\n",
      "\n",
      "Bahrain,738 004\n",
      "\n",
      "Bangladesh,156 118 464\n",
      "\n",
      "Barbados,285 653\n",
      "\n",
      "Belarus,9 685 000\n",
      "\n",
      "Belgium,10 403 000\n",
      "\n",
      "Belize,314 522\n",
      "\n",
      "Benin,9 056 010\n",
      "\n",
      "Bermuda,65 365\n",
      "\n",
      "Bhutan,699 847\n",
      "\n",
      "Bolivia,9 947 418\n",
      "\n",
      "Bonaire, Saint Eustatius and Saba,18 012\n",
      "\n",
      "Bosnia and Herzegovina,4 590 000\n",
      "\n",
      "Botswana,2 029 307\n",
      "\n",
      "Bouvet Island,0\n",
      "\n",
      "Brazil,201 103 330\n",
      "\n",
      "British Indian Ocean Territory,4 000\n",
      "\n",
      "British Virgin Islands,21 730\n",
      "\n",
      "Brunei,395 027\n",
      "\n",
      "Bulgaria,7 148 785\n",
      "\n",
      "Burkina Faso,16 241 811\n",
      "\n",
      "Burundi,9 863 117\n",
      "\n",
      "Cambodia,14 453 680\n",
      "\n",
      "Cameroon,19 294 149\n",
      "\n",
      "Canada,33 679 000\n",
      "\n",
      "Cape Verde,508 659\n",
      "\n",
      "Cayman Islands,44 270\n",
      "\n",
      "Central African Republic,4 844 927\n",
      "\n",
      "Chad,10 543 464\n",
      "\n",
      "Chile,16 746 491\n",
      "\n",
      "Christmas Island,1 500\n",
      "\n",
      "Cocos Islands,628\n",
      "\n",
      "Colombia,44 205 293\n",
      "\n",
      "Comoros,773 407\n",
      "\n",
      "Cook Islands,21 388\n",
      "\n",
      "Costa Rica,4 516 220\n",
      "\n",
      "Croatia,4 491 000\n",
      "\n",
      "Cuba,11 423 000\n",
      "\n",
      "Curacao,141 766\n",
      "\n",
      "Cyprus,1 102 677\n",
      "\n",
      "Czech Republic,10 476 000\n",
      "\n",
      "Democratic Republic of the Congo,70 916 439\n",
      "\n",
      "Denmark,5 484 000\n",
      "\n",
      "Djibouti,740 528\n",
      "\n",
      "Dominica,72 813\n",
      "\n",
      "Dominican Republic,9 823 821\n",
      "\n",
      "East Timor,1 154 625\n",
      "\n",
      "Ecuador,14 790 608\n",
      "\n",
      "Egypt,80 471 869\n",
      "\n",
      "El Salvador,6 052 064\n",
      "\n",
      "Equatorial Guinea,1 014 999\n",
      "\n",
      "Eritrea,5 792 984\n",
      "\n",
      "Estonia,1 291 170\n",
      "\n",
      "Ethiopia,88 013 491\n",
      "\n",
      "Faroe Islands,48 228\n",
      "\n",
      "Fiji,875 983\n",
      "\n",
      "Finland,5 244 000\n",
      "\n",
      "France,64 768 389\n",
      "\n",
      "French Guiana,195 506\n",
      "\n",
      "French Polynesia,270 485\n",
      "\n",
      "French Southern Territories,140\n",
      "\n",
      "Gabon,1 545 255\n",
      "\n",
      "Gambia,1 593 256\n",
      "\n",
      "Georgia,4 630 000\n",
      "\n",
      "Germany,81 802 257\n",
      "\n",
      "Ghana,24 339 838\n",
      "\n",
      "Gibraltar,27 884\n",
      "\n",
      "Greece,11 000 000\n",
      "\n",
      "Greenland,56 375\n",
      "\n",
      "Grenada,107 818\n",
      "\n",
      "Guadeloupe,443 000\n",
      "\n",
      "Guam,159 358\n",
      "\n",
      "Guatemala,13 550 440\n",
      "\n",
      "Guernsey,65 228\n",
      "\n",
      "Guinea,10 324 025\n",
      "\n",
      "Guinea-Bissau,1 565 126\n",
      "\n",
      "Guyana,748 486\n",
      "\n",
      "Haiti,9 648 924\n",
      "\n",
      "Heard Island and McDonald Islands,0\n",
      "\n",
      "Honduras,7 989 415\n",
      "\n",
      "Hungary,9 982 000\n",
      "\n",
      "Iceland,308 910\n",
      "\n",
      "Indonesia,242 968 342\n",
      "\n",
      "Iran,76 923 300\n",
      "\n",
      "Iraq,29 671 605\n",
      "\n",
      "Ireland,4 622 917\n",
      "\n",
      "Isle of Man,75 049\n",
      "\n",
      "Israel,7 353 985\n",
      "\n",
      "Italy,60 340 328\n",
      "\n",
      "Ivory Coast,21 058 798\n",
      "\n",
      "Jamaica,2 847 232\n",
      "\n",
      "Japan,127 288 000\n",
      "\n",
      "Jersey,90 812\n",
      "\n",
      "Jordan,6 407 085\n",
      "\n",
      "Kazakhstan,15 340 000\n",
      "\n",
      "Kenya,40 046 566\n",
      "\n",
      "Kiribati,92 533\n",
      "\n",
      "Kosovo,1 800 000\n",
      "\n",
      "Kuwait,2 789 132\n",
      "\n",
      "Kyrgyzstan,5 508 626\n",
      "\n",
      "Laos,6 368 162\n",
      "\n",
      "Latvia,2 217 969\n",
      "\n",
      "Lebanon,4 125 247\n",
      "\n",
      "Lesotho,1 919 552\n",
      "\n",
      "Liberia,3 685 076\n",
      "\n",
      "Libya,6 461 454\n",
      "\n",
      "Liechtenstein,35 000\n",
      "\n",
      "Lithuania,3 565 000\n",
      "\n",
      "Luxembourg,497 538\n",
      "\n",
      "Macedonia,2 062 294\n",
      "\n",
      "Madagascar,21 281 844\n",
      "\n",
      "Malawi,15 447 500\n",
      "\n",
      "Malaysia,28 274 729\n",
      "\n",
      "Maldives,395 650\n",
      "\n",
      "Mali,13 796 354\n",
      "\n",
      "Malta,403 000\n",
      "\n",
      "Marshall Islands,65 859\n",
      "\n",
      "Martinique,432 900\n",
      "\n",
      "Mauritania,3 205 060\n",
      "\n",
      "Mauritius,1 294 104\n",
      "\n",
      "Mayotte,159 042\n",
      "\n",
      "Mexico,112 468 855\n",
      "\n",
      "Micronesia,107 708\n",
      "\n",
      "Moldova,4 324 000\n",
      "\n",
      "Monaco,32 965\n",
      "\n",
      "Mongolia,3 086 918\n",
      "\n",
      "Montenegro,666 730\n",
      "\n",
      "Montserrat,9 341\n",
      "\n",
      "Morocco,31 627 428\n",
      "\n",
      "Mozambique,22 061 451\n",
      "\n",
      "Myanmar,53 414 374\n",
      "\n",
      "Namibia,2 128 471\n",
      "\n",
      "Nauru,10 065\n",
      "\n",
      "Nepal,28 951 852\n",
      "\n",
      "Netherlands,16 645 000\n",
      "\n",
      "Netherlands Antilles,136 197\n",
      "\n",
      "New Caledonia,216 494\n",
      "\n",
      "New Zealand,4 252 277\n",
      "\n",
      "Nicaragua,5 995 928\n",
      "\n",
      "Niger,15 878 271\n",
      "\n",
      "Nigeria,154 000 000\n",
      "\n",
      "Niue,2 166\n",
      "\n",
      "Norfolk Island,1 828\n",
      "\n",
      "North Korea,22 912 177\n",
      "\n",
      "Northern Mariana Islands,53 883\n",
      "\n",
      "Norway,5 009 150\n",
      "\n",
      "Oman,2 967 717\n",
      "\n",
      "Pakistan,184 404 791\n",
      "\n",
      "Palau,19 907\n",
      "\n",
      "Palestinian Territory,3 800 000\n",
      "\n",
      "Panama,3 410 676\n",
      "\n",
      "Papua New Guinea,6 064 515\n",
      "\n",
      "Paraguay,6 375 830\n",
      "\n",
      "Peru,29 907 003\n",
      "\n",
      "Philippines,99 900 177\n",
      "\n",
      "Pitcairn,46\n",
      "\n",
      "Poland,38 500 000\n",
      "\n",
      "Portugal,10 676 000\n",
      "\n",
      "Puerto Rico,3 916 632\n",
      "\n",
      "Qatar,840 926\n",
      "\n",
      "Republic of the Congo,3 039 126\n",
      "\n",
      "Reunion,776 948\n",
      "\n",
      "Romania,21 959 278\n",
      "\n",
      "Russia,140 702 000\n",
      "\n",
      "Rwanda,11 055 976\n",
      "\n",
      "Saint Barthelemy,8 450\n",
      "\n",
      "Saint Helena,7 460\n",
      "\n",
      "Saint Kitts and Nevis,51 134\n",
      "\n",
      "Saint Lucia,160 922\n",
      "\n",
      "Saint Martin,35 925\n",
      "\n",
      "Saint Pierre and Miquelon,7 012\n",
      "\n",
      "Saint Vincent and the Grenadines,104 217\n",
      "\n",
      "Samoa,192 001\n",
      "\n",
      "San Marino,31 477\n",
      "\n",
      "Sao Tome and Principe,175 808\n",
      "\n",
      "Saudi Arabia,25 731 776\n",
      "\n",
      "Senegal,12 323 252\n",
      "\n",
      "Serbia,7 344 847\n",
      "\n",
      "Serbia and Montenegro,10 829 175\n",
      "\n",
      "Seychelles,88 340\n",
      "\n",
      "Sierra Leone,5 245 695\n",
      "\n",
      "Singapore,4 701 069\n",
      "\n",
      "Sint Maarten,37 429\n",
      "\n",
      "Slovakia,5 455 000\n",
      "\n",
      "Slovenia,2 007 000\n",
      "\n",
      "Solomon Islands,559 198\n",
      "\n",
      "Somalia,10 112 453\n",
      "\n",
      "South Africa,49 000 000\n",
      "\n",
      "South Georgia and the South Sandwich Islands,30\n",
      "\n",
      "South Korea,48 422 644\n",
      "\n",
      "South Sudan,8 260 490\n",
      "\n",
      "Spain,46 505 963\n",
      "\n",
      "Sri Lanka,21 513 990\n",
      "\n",
      "Sudan,35 000 000\n",
      "\n",
      "Suriname,492 829\n",
      "\n",
      "Svalbard and Jan Mayen,2 550\n",
      "\n",
      "Swaziland,1 354 051\n",
      "\n",
      "Sweden,9 555 893\n",
      "\n",
      "Switzerland,7 581 000\n",
      "\n",
      "Syria,22 198 110\n",
      "\n",
      "Tajikistan,7 487 489\n",
      "\n",
      "Tanzania,41 892 895\n",
      "\n",
      "Thailand,67 089 500\n",
      "\n",
      "Togo,6 587 239\n",
      "\n",
      "Tokelau,1 466\n",
      "\n",
      "Tonga,122 580\n",
      "\n",
      "Trinidad and Tobago,1 228 691\n",
      "\n",
      "Tunisia,10 589 025\n",
      "\n",
      "Turkey,77 804 122\n",
      "\n",
      "Turkmenistan,4 940 916\n",
      "\n",
      "Turks and Caicos Islands,20 556\n",
      "\n",
      "Tuvalu,10 472\n",
      "\n",
      "U.S. Virgin Islands,108 708\n",
      "\n",
      "Uganda,33 398 682\n",
      "\n",
      "Ukraine,45 415 596\n",
      "\n",
      "United Arab Emirates,4 975 593\n",
      "\n",
      "United Kingdom,62 348 447\n",
      "\n",
      "United States,310 232 863\n",
      "\n",
      "United States Minor Outlying Islands,0\n",
      "\n",
      "Uruguay,3 477 000\n",
      "\n",
      "Uzbekistan,27 865 738\n",
      "\n",
      "Vanuatu,221 552\n",
      "\n",
      "Vatican,921\n",
      "\n",
      "Venezuela,27 223 228\n",
      "\n",
      "Vietnam,89 571 130\n",
      "\n",
      "Wallis and Futuna,16 025\n",
      "\n",
      "Western Sahara,273 008\n",
      "\n",
      "Yemen,23 495 361\n",
      "\n",
      "Zambia,13 460 305\n",
      "\n",
      "Zimbabwe,11 651 858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#On reprends le code ci-dessus et on va l'enregistrer dans un csv en rajoutant nos lignes de codes\n",
    "\n",
    "\n",
    "with open('urls.txt', 'r') as inf :               #pour input file\n",
    "\n",
    "    with open('pays2.csv', 'w') as outf :          #csv = comma separate value ; pour out file\n",
    "        outf.write('pays,population\\n')           #en-têtes de notre csv ; \\n c'est le retour à la ligne\n",
    "\n",
    "        for row in inf :                               #dans lequel on va itérer              \n",
    "            url = row.strip()                          #permet de ne pas faire de retour à la ligne dans les url (supprime les caractères en début et fin de chaîne)\n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.ok :                  \n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "                country = soup.find('tr', {'id' : 'places_country_or_district__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "                population = soup.find('tr', {'id' : 'places_population__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "                #print('Pays : ' + country.text + ', population : ' +  population.text)\n",
    "                outf.write(country.text + ';'+ population.text+'\\n') #ecriture du fichier csv avec le pays et la population, attention pas d'espace car ce sera un csv\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    with open('pays.csv', 'r') as outf :        \n",
    "        for row in outf:                      \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: #99CCFF\"> **Résoudre le problème des virgules de la population**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pays,population\n",
      "\n",
      "Afghanistan,29 121 286\n",
      "\n",
      "Aland Islands,26 711\n",
      "\n",
      "Albania,2 986 952\n",
      "\n",
      "Algeria,34 586 184\n",
      "\n",
      "American Samoa,57 881\n",
      "\n",
      "Andorra,84 000\n",
      "\n",
      "Angola,13 068 161\n",
      "\n",
      "Anguilla,13 254\n",
      "\n",
      "Antarctica,0\n",
      "\n",
      "Antigua and Barbuda,86 754\n",
      "\n",
      "Argentina,41 343 201\n",
      "\n",
      "Armenia,2 968 000\n",
      "\n",
      "Aruba,71 566\n",
      "\n",
      "Australia,21 515 754\n",
      "\n",
      "Austria,8 205 000\n",
      "\n",
      "Azerbaijan,8 303 512\n",
      "\n",
      "Bahamas,301 790\n",
      "\n",
      "Bahrain,738 004\n",
      "\n",
      "Bangladesh,156 118 464\n",
      "\n",
      "Barbados,285 653\n",
      "\n",
      "Belarus,9 685 000\n",
      "\n",
      "Belgium,10 403 000\n",
      "\n",
      "Belize,314 522\n",
      "\n",
      "Benin,9 056 010\n",
      "\n",
      "Bermuda,65 365\n",
      "\n",
      "Bhutan,699 847\n",
      "\n",
      "Bolivia,9 947 418\n",
      "\n",
      "Bonaire  Saint Eustatius and Saba,18 012\n",
      "\n",
      "Bosnia and Herzegovina,4 590 000\n",
      "\n",
      "Botswana,2 029 307\n",
      "\n",
      "Bouvet Island,0\n",
      "\n",
      "Brazil,201 103 330\n",
      "\n",
      "British Indian Ocean Territory,4 000\n",
      "\n",
      "British Virgin Islands,21 730\n",
      "\n",
      "Brunei,395 027\n",
      "\n",
      "Bulgaria,7 148 785\n",
      "\n",
      "Burkina Faso,16 241 811\n",
      "\n",
      "Burundi,9 863 117\n",
      "\n",
      "Cambodia,14 453 680\n",
      "\n",
      "Cameroon,19 294 149\n",
      "\n",
      "Canada,33 679 000\n",
      "\n",
      "Cape Verde,508 659\n",
      "\n",
      "Cayman Islands,44 270\n",
      "\n",
      "Central African Republic,4 844 927\n",
      "\n",
      "Chad,10 543 464\n",
      "\n",
      "Chile,16 746 491\n",
      "\n",
      "Christmas Island,1 500\n",
      "\n",
      "Cocos Islands,628\n",
      "\n",
      "Colombia,44 205 293\n",
      "\n",
      "Comoros,773 407\n",
      "\n",
      "Cook Islands,21 388\n",
      "\n",
      "Costa Rica,4 516 220\n",
      "\n",
      "Croatia,4 491 000\n",
      "\n",
      "Cuba,11 423 000\n",
      "\n",
      "Curacao,141 766\n",
      "\n",
      "Cyprus,1 102 677\n",
      "\n",
      "Czech Republic,10 476 000\n",
      "\n",
      "Democratic Republic of the Congo,70 916 439\n",
      "\n",
      "Denmark,5 484 000\n",
      "\n",
      "Djibouti,740 528\n",
      "\n",
      "Dominica,72 813\n",
      "\n",
      "Dominican Republic,9 823 821\n",
      "\n",
      "East Timor,1 154 625\n",
      "\n",
      "Ecuador,14 790 608\n",
      "\n",
      "Egypt,80 471 869\n",
      "\n",
      "El Salvador,6 052 064\n",
      "\n",
      "Equatorial Guinea,1 014 999\n",
      "\n",
      "Eritrea,5 792 984\n",
      "\n",
      "Estonia,1 291 170\n",
      "\n",
      "Ethiopia,88 013 491\n",
      "\n",
      "Faroe Islands,48 228\n",
      "\n",
      "Fiji,875 983\n",
      "\n",
      "Finland,5 244 000\n",
      "\n",
      "France,64 768 389\n",
      "\n",
      "French Guiana,195 506\n",
      "\n",
      "French Polynesia,270 485\n",
      "\n",
      "French Southern Territories,140\n",
      "\n",
      "Gabon,1 545 255\n",
      "\n",
      "Gambia,1 593 256\n",
      "\n",
      "Georgia,4 630 000\n",
      "\n",
      "Germany,81 802 257\n",
      "\n",
      "Ghana,24 339 838\n",
      "\n",
      "Gibraltar,27 884\n",
      "\n",
      "Greece,11 000 000\n",
      "\n",
      "Greenland,56 375\n",
      "\n",
      "Grenada,107 818\n",
      "\n",
      "Guadeloupe,443 000\n",
      "\n",
      "Guam,159 358\n",
      "\n",
      "Guatemala,13 550 440\n",
      "\n",
      "Guernsey,65 228\n",
      "\n",
      "Guinea,10 324 025\n",
      "\n",
      "Guinea-Bissau,1 565 126\n",
      "\n",
      "Guyana,748 486\n",
      "\n",
      "Haiti,9 648 924\n",
      "\n",
      "Heard Island and McDonald Islands,0\n",
      "\n",
      "Honduras,7 989 415\n",
      "\n",
      "Hungary,9 982 000\n",
      "\n",
      "Iceland,308 910\n",
      "\n",
      "Indonesia,242 968 342\n",
      "\n",
      "Iran,76 923 300\n",
      "\n",
      "Iraq,29 671 605\n",
      "\n",
      "Ireland,4 622 917\n",
      "\n",
      "Isle of Man,75 049\n",
      "\n",
      "Israel,7 353 985\n",
      "\n",
      "Italy,60 340 328\n",
      "\n",
      "Ivory Coast,21 058 798\n",
      "\n",
      "Jamaica,2 847 232\n",
      "\n",
      "Japan,127 288 000\n",
      "\n",
      "Jersey,90 812\n",
      "\n",
      "Jordan,6 407 085\n",
      "\n",
      "Kazakhstan,15 340 000\n",
      "\n",
      "Kenya,40 046 566\n",
      "\n",
      "Kiribati,92 533\n",
      "\n",
      "Kosovo,1 800 000\n",
      "\n",
      "Kuwait,2 789 132\n",
      "\n",
      "Kyrgyzstan,5 508 626\n",
      "\n",
      "Laos,6 368 162\n",
      "\n",
      "Latvia,2 217 969\n",
      "\n",
      "Lebanon,4 125 247\n",
      "\n",
      "Lesotho,1 919 552\n",
      "\n",
      "Liberia,3 685 076\n",
      "\n",
      "Libya,6 461 454\n",
      "\n",
      "Liechtenstein,35 000\n",
      "\n",
      "Lithuania,3 565 000\n",
      "\n",
      "Luxembourg,497 538\n",
      "\n",
      "Macedonia,2 062 294\n",
      "\n",
      "Madagascar,21 281 844\n",
      "\n",
      "Malawi,15 447 500\n",
      "\n",
      "Malaysia,28 274 729\n",
      "\n",
      "Maldives,395 650\n",
      "\n",
      "Mali,13 796 354\n",
      "\n",
      "Malta,403 000\n",
      "\n",
      "Marshall Islands,65 859\n",
      "\n",
      "Martinique,432 900\n",
      "\n",
      "Mauritania,3 205 060\n",
      "\n",
      "Mauritius,1 294 104\n",
      "\n",
      "Mayotte,159 042\n",
      "\n",
      "Mexico,112 468 855\n",
      "\n",
      "Micronesia,107 708\n",
      "\n",
      "Moldova,4 324 000\n",
      "\n",
      "Monaco,32 965\n",
      "\n",
      "Mongolia,3 086 918\n",
      "\n",
      "Montenegro,666 730\n",
      "\n",
      "Montserrat,9 341\n",
      "\n",
      "Morocco,31 627 428\n",
      "\n",
      "Mozambique,22 061 451\n",
      "\n",
      "Myanmar,53 414 374\n",
      "\n",
      "Namibia,2 128 471\n",
      "\n",
      "Nauru,10 065\n",
      "\n",
      "Nepal,28 951 852\n",
      "\n",
      "Netherlands,16 645 000\n",
      "\n",
      "Netherlands Antilles,136 197\n",
      "\n",
      "New Caledonia,216 494\n",
      "\n",
      "New Zealand,4 252 277\n",
      "\n",
      "Nicaragua,5 995 928\n",
      "\n",
      "Niger,15 878 271\n",
      "\n",
      "Nigeria,154 000 000\n",
      "\n",
      "Niue,2 166\n",
      "\n",
      "Norfolk Island,1 828\n",
      "\n",
      "North Korea,22 912 177\n",
      "\n",
      "Northern Mariana Islands,53 883\n",
      "\n",
      "Norway,5 009 150\n",
      "\n",
      "Oman,2 967 717\n",
      "\n",
      "Pakistan,184 404 791\n",
      "\n",
      "Palau,19 907\n",
      "\n",
      "Palestinian Territory,3 800 000\n",
      "\n",
      "Panama,3 410 676\n",
      "\n",
      "Papua New Guinea,6 064 515\n",
      "\n",
      "Paraguay,6 375 830\n",
      "\n",
      "Peru,29 907 003\n",
      "\n",
      "Philippines,99 900 177\n",
      "\n",
      "Pitcairn,46\n",
      "\n",
      "Poland,38 500 000\n",
      "\n",
      "Portugal,10 676 000\n",
      "\n",
      "Puerto Rico,3 916 632\n",
      "\n",
      "Qatar,840 926\n",
      "\n",
      "Republic of the Congo,3 039 126\n",
      "\n",
      "Reunion,776 948\n",
      "\n",
      "Romania,21 959 278\n",
      "\n",
      "Russia,140 702 000\n",
      "\n",
      "Rwanda,11 055 976\n",
      "\n",
      "Saint Barthelemy,8 450\n",
      "\n",
      "Saint Helena,7 460\n",
      "\n",
      "Saint Kitts and Nevis,51 134\n",
      "\n",
      "Saint Lucia,160 922\n",
      "\n",
      "Saint Martin,35 925\n",
      "\n",
      "Saint Pierre and Miquelon,7 012\n",
      "\n",
      "Saint Vincent and the Grenadines,104 217\n",
      "\n",
      "Samoa,192 001\n",
      "\n",
      "San Marino,31 477\n",
      "\n",
      "Sao Tome and Principe,175 808\n",
      "\n",
      "Saudi Arabia,25 731 776\n",
      "\n",
      "Senegal,12 323 252\n",
      "\n",
      "Serbia,7 344 847\n",
      "\n",
      "Serbia and Montenegro,10 829 175\n",
      "\n",
      "Seychelles,88 340\n",
      "\n",
      "Sierra Leone,5 245 695\n",
      "\n",
      "Singapore,4 701 069\n",
      "\n",
      "Sint Maarten,37 429\n",
      "\n",
      "Slovakia,5 455 000\n",
      "\n",
      "Slovenia,2 007 000\n",
      "\n",
      "Solomon Islands,559 198\n",
      "\n",
      "Somalia,10 112 453\n",
      "\n",
      "South Africa,49 000 000\n",
      "\n",
      "South Georgia and the South Sandwich Islands,30\n",
      "\n",
      "South Korea,48 422 644\n",
      "\n",
      "South Sudan,8 260 490\n",
      "\n",
      "Spain,46 505 963\n",
      "\n",
      "Sri Lanka,21 513 990\n",
      "\n",
      "Sudan,35 000 000\n",
      "\n",
      "Suriname,492 829\n",
      "\n",
      "Svalbard and Jan Mayen,2 550\n",
      "\n",
      "Swaziland,1 354 051\n",
      "\n",
      "Sweden,9 555 893\n",
      "\n",
      "Switzerland,7 581 000\n",
      "\n",
      "Syria,22 198 110\n",
      "\n",
      "Tajikistan,7 487 489\n",
      "\n",
      "Tanzania,41 892 895\n",
      "\n",
      "Thailand,67 089 500\n",
      "\n",
      "Togo,6 587 239\n",
      "\n",
      "Tokelau,1 466\n",
      "\n",
      "Tonga,122 580\n",
      "\n",
      "Trinidad and Tobago,1 228 691\n",
      "\n",
      "Tunisia,10 589 025\n",
      "\n",
      "Turkey,77 804 122\n",
      "\n",
      "Turkmenistan,4 940 916\n",
      "\n",
      "Turks and Caicos Islands,20 556\n",
      "\n",
      "Tuvalu,10 472\n",
      "\n",
      "U.S. Virgin Islands,108 708\n",
      "\n",
      "Uganda,33 398 682\n",
      "\n",
      "Ukraine,45 415 596\n",
      "\n",
      "United Arab Emirates,4 975 593\n",
      "\n",
      "United Kingdom,62 348 447\n",
      "\n",
      "United States,310 232 863\n",
      "\n",
      "United States Minor Outlying Islands,0\n",
      "\n",
      "Uruguay,3 477 000\n",
      "\n",
      "Uzbekistan,27 865 738\n",
      "\n",
      "Vanuatu,221 552\n",
      "\n",
      "Vatican,921\n",
      "\n",
      "Venezuela,27 223 228\n",
      "\n",
      "Vietnam,89 571 130\n",
      "\n",
      "Wallis and Futuna,16 025\n",
      "\n",
      "Western Sahara,273 008\n",
      "\n",
      "Yemen,23 495 361\n",
      "\n",
      "Zambia,13 460 305\n",
      "\n",
      "Zimbabwe,11 651 858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#il faut remplacer les virgules de la population par rien\n",
    "\n",
    "with open('urls.txt', 'r') as inf :               \n",
    "\n",
    "    with open('pays2.csv', 'w') as outf :          \n",
    "        outf.write('pays,population\\n')           \n",
    "\n",
    "        for row in inf :                                          \n",
    "            url = row.strip()                          \n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.ok :                  \n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "                country = soup.find('tr', {'id' : 'places_country_or_district__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "                population = soup.find('tr', {'id' : 'places_population__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "                #print('Pays : ' + country.text + ', population : ' +  population.text)\n",
    "                outf.write(country.text.replace(',',' ') + ','+ population.text.replace(',',' ') +'\\n')               # .replace la , par rien\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    with open('pays2.csv', 'r') as outf :        \n",
    "        for row in outf:                      \n",
    "            print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pays</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>29 121 286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aland Islands</td>\n",
       "      <td>26 711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2 986 952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>34 586 184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>57 881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pays  population\n",
       "0     Afghanistan  29 121 286\n",
       "1   Aland Islands      26 711\n",
       "2         Albania   2 986 952\n",
       "3         Algeria  34 586 184\n",
       "4  American Samoa      57 881"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajout dans un df, vous pouvez tout relancer si vous copier ce bout de code sinon juste le \"df\"\n",
    "\n",
    "'''with open('urls.txt', 'r') as inf :               \n",
    "\n",
    "    with open('pays.csv', 'w') as outf :          \n",
    "        outf.write('pays,population\\n')           \n",
    "\n",
    "        for row in inf :                                          \n",
    "            url = row.strip()                          \n",
    "            response = requests.get(url)\n",
    "\n",
    "            if response.ok :                  \n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "                country = soup.find('tr', {'id' : 'places_country_or_district__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "                population = soup.find('tr', {'id' : 'places_population__row'}).find('td', {'class' : 'w2p_fw'})\n",
    "                #print('Pays : ' + country.text + ', population : ' +  population.text)\n",
    "                outf.write(country.text + ','+ population.text.replace(',','') +'\\n')               \n",
    "        time.sleep(1)\n",
    "\n",
    "    with open('pays.csv', 'r') as outf :        \n",
    "        for row in outf:                      \n",
    "            print(row)'''\n",
    "\n",
    "\n",
    "df = pd.read_csv('pays2.csv')\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà c'est terminé, nous avons scrappé plusieurs pages d'un site !\n",
    "Prochain tuto, scrapper instagram !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3755b735588d4303beb95518f2ab4e1c49ea1461d509c805a65d62cd2a8f700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
